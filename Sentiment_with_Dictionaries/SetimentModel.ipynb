{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from razdel import tokenize\n",
    "from pymystem3 import Mystem\n",
    "from slovnet import Morph, Syntax\n",
    "from ipymarkup import show_dep_ascii_markup as show_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = []\n",
    "    with open('data.txt', 'r', encoding='utf8') as lines:\n",
    "        for line in lines:\n",
    "            data.append([_.text for _ in tokenize(line.split('\\t')[0])])\n",
    "            data.append([_.text for _ in tokenize(line.split('\\t')[1].strip())])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_dict(fname):\n",
    "    d = {}\n",
    "    with open(fname, 'r', encoding='utf8') as lines:\n",
    "        if 'particles' in fname:\n",
    "            return [l.strip() for l in lines]\n",
    "        for line in lines:\n",
    "            key, item = line.strip().split('\\t')\n",
    "            d[key] = int(item)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts():\n",
    "    d = {}\n",
    "    \n",
    "    d['ADJ_NEG'] = get_a_dict('./RUS/adjectives/list_adjectives_neg_utf.txt')\n",
    "    d['ADJ_POS'] = get_a_dict('./RUS/adjectives/list_adjectives_pos_utf.txt')\n",
    "    d['ADJ_AMPLF'] = get_a_dict('./RUS/adjectives/list_adjectives_amplf_utf.txt')\n",
    "    \n",
    "    d['ADV_NEG'] = get_a_dict('./RUS/adverbs/list_adverbs_neg_utf.txt')\n",
    "    d['ADV_POS'] = get_a_dict('./RUS/adverbs/list_adverbs_pos_utf.txt')\n",
    "    d['ADV_AMPLF'] = get_a_dict('./RUS/adverbs/list_adverbs_amplf_utf.txt')\n",
    "    \n",
    "    d['NOUN_NEG'] = get_a_dict('./RUS/nouns/list_nouns_neg_utf.txt')\n",
    "    d['NOUN_POS'] = get_a_dict('./RUS/nouns/list_nouns_pos_utf.txt')\n",
    "    d['NOUN_ANEG'] = get_a_dict('./RUS/nouns/list_nouns_aneg_utf.txt')\n",
    "    d['NOUN_APOS'] = get_a_dict('./RUS/nouns/list_nouns_apos_utf.txt')\n",
    "    \n",
    "    d['VERB_FLX_NEG'] = get_a_dict('./RUS/verbs/list_verbs_flxneg_utf.txt')\n",
    "    d['VERB_FLX_POS'] = get_a_dict('./RUS/verbs/list_verbs_flxpos_utf.txt')\n",
    "    d['VERB_NEG'] = get_a_dict('./RUS/verbs/list_verbs_neg_utf.txt')\n",
    "    d['VERB_P_NEG'] = get_a_dict('./RUS/verbs/list_verbs_pure_neg_utf.txt')\n",
    "    d['VERB_OPP_NEG'] = get_a_dict('./RUS/verbs/list_verbs_opp_neg_utf.txt')\n",
    "    d['VERB_OPP_POS'] = get_a_dict('./RUS/verbs/list_verbs_opp_pos_utf.txt')\n",
    "    d['VERB_POS'] = get_a_dict('./RUS/verbs/list_verbs_pos_utf.txt')\n",
    "    d['VERB_P_POS'] = get_a_dict('./RUS/verbs/list_verbs_opp_pos_utf.txt')\n",
    "    \n",
    "    d['COL_VPOS'] = get_a_dict('./RUS/collocations/list_collocation_vpos_utf.txt')\n",
    "    d['COL_VNEG'] = get_a_dict('./RUS/collocations/list_collocation_vneg_utf.txt')\n",
    "    d['COL_VNEUT'] = get_a_dict('./RUS/collocations/list_collocation_vneut_utf.txt')\n",
    "    d['COL_POS'] = get_a_dict('./RUS/collocations/list_collocation_pos_utf.txt')\n",
    "    d['COL_NEG'] = get_a_dict('./RUS/collocations/list_collocation_neg_utf.txt')\n",
    "    d['COL_NEUT'] = get_a_dict('./RUS/collocations/list_collocation_neut_utf.txt')\n",
    "    d['COL_AMPLF'] = get_a_dict('./RUS/collocations/list_collocation_amplf_utf.txt')\n",
    "    \n",
    "    d['IMPOS'] = get_a_dict('./RUS/polarity/impossibility_utf.txt')\n",
    "    d['AMPLF'] = get_a_dict('./RUS/polarity/amplificators_utf.txt')\n",
    "    d['INVERT_POLARITY'] = get_a_dict('./RUS/polarity/inversion_polarity_utf.txt')\n",
    "    d['INVERT_POLARITY_PRED'] = get_a_dict('./RUS/polarity/inversion_polarity_predication_utf.txt')\n",
    "    d['INVERT_POLARITY_SHIFT_NEG'] = get_a_dict('./RUS/polarity/inversion_polarity_shifters_neg_utf.txt')\n",
    "    d['INVERT_POLARITY_SHIFT_POS'] = get_a_dict('./RUS/polarity/inversion_polarity_shifters_pos_utf.txt')\n",
    "    d['INVERT_POLARITY_PARTICLE'] = get_a_dict('./RUS/polarity/inversion_polarity_particles.txt')\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1():\n",
    "    data = get_data()\n",
    "    d = get_dicts()\n",
    "    m = Mystem()\n",
    "    \n",
    "    navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "    morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\n",
    "    morph.navec(navec)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    markups = morph.map(data)\n",
    "    for markup in markups:\n",
    "        for sentence in markup:\n",
    "            item = []\n",
    "            for token in sentence:\n",
    "                n = 0\n",
    "                tag = token.tag.split('|')[0] + '_NEUT'\n",
    "                lem = m.lemmatize(token.text)[0]\n",
    "                for t in d.keys():\n",
    "                    if lem in d[t]:\n",
    "                        if t == 'INVERT_POLARITY_PARTICLE':\n",
    "                            n = 0\n",
    "                            tag = t\n",
    "                            continue\n",
    "                        n = d[t][lem]\n",
    "                        tag = t\n",
    "                item.append('\\t'.join([token.text, lem, str(n), tag]))\n",
    "        res.append(item)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2():\n",
    "    data = get_data()\n",
    "    \n",
    "    navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "    syntax = Syntax.load('slovnet_syntax_news_v1.tar')\n",
    "    syntax.navec(navec)\n",
    "    \n",
    "    markups = syntax.map(data)\n",
    "    \n",
    "    words, deps = [], []\n",
    "    \n",
    "    for markup in markups:\n",
    "        for sentence in markup:\n",
    "            word = []\n",
    "            dep = []\n",
    "            for token in sentence:\n",
    "                word.append(token.text)\n",
    "                source = int(token.head_id) - 1\n",
    "                target = int(token.id) - 1\n",
    "                #print(token.text, token.head_id, token.id, token.rel)\n",
    "                #if source > 0 and source != target:  # skip root, loops\n",
    "                dep.append([source, target, token.rel])\n",
    "            words.append(word)\n",
    "            deps.append(dep)\n",
    "            #print(word, dep)\n",
    "            #show_markup(word, dep)\n",
    "            #print()\n",
    "            \n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        item = []\n",
    "        for j in range(len(words[i])):\n",
    "            item.append('\\t'.join([words[i][j], str(deps[i][j][0]), str(deps[i][j][1]), deps[i][j][2]]))\n",
    "        res.append(item)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphs = stage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synts = stage2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(morphs)):\n",
    "    item = []\n",
    "    for j in range(len(morphs[i])):\n",
    "        item.append(morphs[i][j] + '\\t' + synts[i][j].split('\\t', 1)[1])\n",
    "    res.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent(sent):\n",
    "    is_amplf = 0\n",
    "\n",
    "    s = 0\n",
    "    for w in sent:\n",
    "        if 'AMPLF' in w:\n",
    "            is_amplf = int(w.split('\\t')[2])\n",
    "            \n",
    "        elif 'NEG' in w:\n",
    "            s -= int(w.split('\\t')[2])\n",
    "            s -= 1\n",
    "            if 'root' in w:\n",
    "                s -= 1\n",
    "            if is_amplf:\n",
    "                s -= is_amplf\n",
    "                is_amplf = 0\n",
    "\n",
    "        elif 'POS' in w:\n",
    "            s += int(w.split('\\t')[2])\n",
    "            s += 1\n",
    "            if 'root' in w:\n",
    "                s += 1\n",
    "            if is_amplf:\n",
    "                s += is_amplf\n",
    "                is_amplf = 0\n",
    "        \n",
    "        else:\n",
    "            is_amplf = 0\n",
    "            \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data.txt', 'r', encoding='utf8') as lines:\n",
    "        for line in lines:\n",
    "            data.append(line.split('\\t')[0])\n",
    "            data.append(line.split('\\t')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.txt', 'w', encoding='utf8') as ouf:\n",
    "    for i, sent in enumerate(res):\n",
    "        s = get_sent(sent)\n",
    "        if s == 0:\n",
    "            s = 'neutral'\n",
    "        elif s > 0:\n",
    "            s = 'positive'\n",
    "        else:\n",
    "            s = 'negative'\n",
    "        ouf.write(data[i] + '\\t' + s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 53, 'positive': 83, 'negative': 104}\n"
     ]
    }
   ],
   "source": [
    "d = {'neutral': 0, 'positive': 0, 'negative': 0}\n",
    "\n",
    "for i, sent in enumerate(res):\n",
    "    s = get_sent(sent)\n",
    "    if s == 0:\n",
    "        d['neutral'] += 1\n",
    "    elif s > 0:\n",
    "        d['positive'] += 1\n",
    "    else:\n",
    "        d['negative'] += 1\n",
    "        \n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
