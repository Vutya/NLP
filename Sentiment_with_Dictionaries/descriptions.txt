МОДЕЛЬ САНТИМЕНТА
Данная модель была создана для анализа тональности новостных заголовков. В её основе лежат тональные словари и система правил для оценки тональности заголовка. Подробнее об используемых словарях можно узнать в [1].
Анализ тональности в нашем случае работает в 3 этапа. Первый этап включает в себя токенизацию, лемматизацию, частеречную разметку и присваивание тональности каждому слову и каждой коллокации по тональному словарю. Если слово не встречается в словаре, то мы считаем его нейтрально окрашенным. Также отдельно были обозначены слова, инвертирующие тональность текста ("не", "зря", "ложь"). Лемматизация проводилась с помощью библиотеки Mystem, частеречная разметка - с помощью библиотеки Slovnet [2].
На втором этапе с помощью всё той же библиотеки Slovnet проводится синтаксический анализ, и в результате получается синтаксическое дерево для каждого заголовка. Корнем дерева обычно является сказуемое, из него отходят ветви в подлежащее и в придаточные предложения (см. примеры в [2]). Далее, по набору правил и полученному дереву все слова объединяются в цепочки слов.
На третьем этапе для этих цепочек слов мы высчитываем силу сантимента по следующим правилам. У каждого элемента словаря есть не только обозначение его положительности, отрицательности или нейтральности, но и сила этого сантимента. Слабый сантимент имеет вес +-1, средний +-2, а сильный +-3 (знак зависит от положительности или отрицательности). В полученных цепочках для каждого слова и каждой коллокации полученные веса складываются. При этом если в цепочке присутствует инвертор, то знак тональности цепочки меняется на противоположный. Также учитываются специальные усиливающие слова, которые придают дополнительные веса к слову с тональностью. Корень также получает дополнительный вес. Затем по такому же принципу суммирования мы складываем веса для всех цепочек слов в предложении и получаем суммарную тональность заголовка. В конце модель в качестве сантимента берёт знак полученного веса и в зависимости от результата приписывает каждому заголовку один их трёх классов: positive, negative или neutral.
Приведём несколько более специфических примеров использования синтаксических деревьев и оценки тональностей. Например, в этой паре предложений каждому моделью была предписана отрицательная оценка тональности, причём корень "упал" в обоих получил дополнительный отрицательный вес: 
Гитарист U2 упал со сцены во время концерта в Ванкувере	negative
Гитарист группы U2 упал со сцены	negative
Далее приведён пример усилителя тональности. Усиливающее слово "впервые" даёт дополнительный весй слову "издан", имеющему слабую положительную тональность:
Переведенный на армянский язык Коран впервые издан в Турции	positive
Следующая пара также показалась интересной:
Марадона заявил, что наслаждался, наблюдая за арестами чиновников ФИФА	positive
Путин прокомментировал роль США в арестах чиновников ФИФА	negative
Оба предложения получили разную оценку тональности, хотя и в целом они похожи. В первом высказывается положительное отношение субъекта к отрицательному событию. Во втором же отношение субъекта (Путина) не раскрывается - говорится только о нейтральном действиии "прокомментировал" относительно отрицательного события (арестов).
Неудачным примером работы модели можно назвать следующую пару:
В Непале зафиксировано новое землетрясение силой 7 баллов	positive
В Непале произошло землетрясение магнитудой 7,4	negative
В первом случае положительным оказался корень, из-за чего сила положительного сантимента была увеличена. Также слово "силой" имело положительную оценку, а слово "землетрясение" было единственным отрицательным словом. Во втором случае все слова оказались нейтральными, кроме слова "землетрясение", что и повлияло на полученную оценку тональности.

1. А.Г. Пазельская, А.Н. Соловьёв, "Метод определения эмоций в текстах на русском языке" // Материалы конференции "Диалог" (2011).
2. Репозиторий библиотеки Slovnet, https://github.com/natasha/slovnet



МОДЕЛЬ ПАРАФРАЗ
Для задачи распознавания парафраз среди новостоных заголовков на русском языке был выбран подход на основе машинного обучения - проект Paraphraser [1] предоставляет достаточное количество данных для работы в таком подходе. В качестве тренировочной части датасета был взят основной корпуса парафраз, в котором содержится 7227 размеченных пар новостных заголовков. Тестовые даннные взяты из так называемого "золотого набора" парафраз, в котором размечены 1924 пары заголовков.
Предобработка текста включает в себя токенизацию, лемматизацию и сохранение токенов в формате "лемма_POS", где POS - это тэг части речи. На этом этапе использовалась библиотека Mystem3. Следующий этап - векторизация текстовых данных. Для этого была использована предобученная на новостных текстах word2vec-модель, взятая с проекта RusVectores [2] (размер окна = 20, размерность вектора = 1000, алгоритм = Continuous Skip-Gram, объём словаря = 147 358). Также для каждого слова в тренировочном корпусе был посчитан TF-IDF. В тестовом корпусе для слов, не входящих в тренировочный набор, TF-IDF вычисляется как средний TF-IDF для синонимов этого слова, входящих в тренировочный корпус. Зачем нам нужен TF-IDF? Векторизация новостного заголовка представлет собой взвешенную сумму векторов всех слов, входящих в этот заголовок. Вес слова - это его TF-IDF, а сам вектор слова берётся из упомянутой выше word2vec модели. Также используется несколько дополнительных признаков - сумма векторов двух заголовков в паре парафраз, модуль их разности, косинусное расстояние между ними и мера Жаккарда для лемм в обоих предложениях.
Для этого набора признаков было протестировано несколько разных моделей (SVM, логистическая регрессия, Random Forest), но логистическая регрессия показала себя лучше всего (F1_micro = 0.60, F1_macro = 0.55)

1. Официальный сайт проекта Paraphraser, http://paraphraser.ru/
2. Модели от RusVectores, https://rusvectores.org/ru/models/
